{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ba175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pymysql\n",
    "import openai\n",
    "import argparse\n",
    "import getpass\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from cryptography.fernet import Fernet, InvalidToken\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n",
    "import base64\n",
    "import platform  # Import platform module to clear the screen\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003df77",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up argument parser\n",
    "parser = argparse.ArgumentParser(description='Fetch Singlestore and API AI Key')\n",
    "parser.add_argument('--master-password', type=str, help='Master password for the credential store')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf84c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SALT_FILE = 'salt.key'\n",
    "CREDENTIALS_FILE = 'credentials.enc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bfe234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if credential files exist\n",
    "credentials_exist = os.path.exists(CREDENTIALS_FILE) and os.path.exists(SALT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4828f14",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "master_password = None\n",
    "master_key = None\n",
    "openai_credentials = {}\n",
    "singlestore_credentials = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e3bed",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_salt():\n",
    "    \"\"\"Retrieve or generate a salt for key derivation.\"\"\"\n",
    "    if os.path.exists(SALT_FILE):\n",
    "        with open(SALT_FILE, 'rb') as file:\n",
    "            return file.read()\n",
    "    else:\n",
    "        salt = os.urandom(16)\n",
    "        with open(SALT_FILE, 'wb') as file:\n",
    "            file.write(salt)\n",
    "        return salt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b820d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def derive_key(password: str, salt: bytes) -> bytes:\n",
    "    \"\"\"Derive a key from a password and salt.\"\"\"\n",
    "    kdf = PBKDF2HMAC(\n",
    "        algorithm=hashes.SHA256(),\n",
    "        length=32,\n",
    "        salt=salt,\n",
    "        iterations=100000,\n",
    "        backend=default_backend()\n",
    "    )\n",
    "    return base64.urlsafe_b64encode(kdf.derive(password.encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73069ec0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# New function to retrieve SingleStore and OpenAI credentials\n",
    "def get_credentials(master_key, service_type):\n",
    "    \"\"\"Retrieve credentials for a specific service from the encrypted file.\"\"\"\n",
    "    try:\n",
    "        with open(CREDENTIALS_FILE, 'rb') as file:\n",
    "            encrypted_data = file.read()\n",
    "        f = Fernet(master_key)\n",
    "        decrypted_data = f.decrypt(encrypted_data)\n",
    "        credentials = json.loads(decrypted_data.decode())\n",
    "        return credentials.get(service_type, {})\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving credentials for {service_type}: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6dfb9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def clear_screen():\n",
    "    \"\"\"Clear the terminal screen based on the operating system.\"\"\"\n",
    "    if platform.system() == 'Windows':\n",
    "        os.system('cls')  # For Windows\n",
    "    else:\n",
    "        os.system('clear')  # For Linux/Unix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befd5d9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Custom function to truncate or insert line breaks\n",
    "def format_text(text, max_length=100):\n",
    "    return text if len(text) <= max_length else text[:max_length] + '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c864f48",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Apply the function to your DataFrame\n",
    "def format_dataframe(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:  # Apply only to string columns\n",
    "            df[col] = df[col].apply(lambda x: format_text(x, 100))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781aae52",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Function to get embeddings using OpenAI\n",
    "def get_embeddings(text):\n",
    "    response = openai.Embedding.create(input=[text], engine=\"text-embedding-ada-002\")\n",
    "    return response['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08e158",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Function to get embeddings using sentence-transformers (MiniLM)\n",
    "def get_minilm_embeddings(text):\n",
    "    # Generate embeddings\n",
    "    embeddings = model.encode(text, convert_to_numpy=True)\n",
    "    return embeddings.tolist()  # Convert numpy array to list for compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48669d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve master password and derive master key\n",
    "if credentials_exist:\n",
    "        # Retrieve master password\n",
    "    if args.master_password:\n",
    "        master_password = args.master_password\n",
    "    else:\n",
    "        master_password = getpass.getpass(\"Enter master password: \")\n",
    "    salt = get_salt()\n",
    "    master_key = derive_key(master_password, salt)\n",
    "\n",
    "    # Load OpenAI and SingleStore credentials from encrypted file\n",
    "    openai_credentials = get_credentials(master_key, 'openai')\n",
    "    singlestore_credentials = get_credentials(master_key, 'singlestore')\n",
    "\n",
    "    # Set OpenAI API key\n",
    "    openai.api_key = openai_credentials.get('api_key')\n",
    "\n",
    "    # Display SingleStore credentials if retrieved\n",
    "    if singlestore_credentials:\n",
    "        print(f\"SingleStore Host: {singlestore_credentials.get('hostname')}, \"\n",
    "              f\"Port: {singlestore_credentials.get('port')}, \"\n",
    "              f\"Database: {singlestore_credentials.get('database')}\")\n",
    "    else:\n",
    "        print(\"Unable to retrieve SingleStore credentials.\")\n",
    "else:\n",
    "    print(\"Credential files not found. Exiting.\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OpenAI and SingleStore credentials from the encrypted file\n",
    "openai_credentials = get_credentials(master_key, 'openai')\n",
    "singlestore_credentials = get_credentials(master_key, 'singlestore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da12c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API key\n",
    "openai.api_key = openai_credentials.get('api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf55ea",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if not singlestore_credentials:\n",
    "    print(\"SingleStore credentials not provided. Skipping database operations.\")\n",
    "    exit()  # Exit the script if credentials are not provided\n",
    "else:\n",
    "    print(\"SingleStore credentials provided.\")\n",
    "\n",
    "    ssl_config = {'ca': 'singlestore_bundle.pem'}\n",
    "\n",
    "    try:\n",
    "        connection = pymysql.connect(\n",
    "            host=singlestore_credentials.get('hostname'),\n",
    "            port=int(singlestore_credentials.get('port', 3306)),\n",
    "            user=singlestore_credentials.get('username'),\n",
    "            password=singlestore_credentials.get('password'),\n",
    "            database=singlestore_credentials.get('database'),\n",
    "            ssl=ssl_config\n",
    "        )\n",
    "\n",
    "        # Create a cursor object here\n",
    "        cursor = connection.cursor()\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to the database: {e}\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8804b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch top 5 results grouped by topic\n",
    "def fetch_top__results_grouped_by_topic(search_string):\n",
    "    search_embedding_openai = json.dumps(get_embeddings(search_string))\n",
    "    #search_embedding_minilm = json.dumps(get_minilm_embeddings(search_string))\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        a.topic,\n",
    "        SUM(DOT_PRODUCT(c.comment_vector, JSON_ARRAY_PACK('{search_embedding_openai}'))) / COUNT(c.comment_text) AS average_score_per_comment,\n",
    "        COUNT(DISTINCT c.comment_text) AS distinct_comment_count,\n",
    "        COUNT(DISTINCT a.post_shortcode) AS distinct_post_count\n",
    "    FROM\n",
    "        posts a\n",
    "    JOIN\n",
    "        comments c ON a.post_shortcode = c.post_shortcode\n",
    "    GROUP BY a.topic\n",
    "    ORDER BY average_score_per_comment DESC\n",
    "    LIMIT 20;\n",
    "    \"\"\"\n",
    "    #print(query)\n",
    "\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        results = cursor.fetchall()\n",
    "\n",
    "        # Convert results to DataFrame\n",
    "        df = pd.DataFrame(results, columns=['Topic', 'Score','Count_Comments', 'Count_Posts'])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8722e382",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Function to fetch results based on search string\n",
    "def fetch_results(search_string):\n",
    "    search_embedding_openai = json.dumps(get_embeddings(search_string))\n",
    "    search_embedding_minilm = json.dumps(get_minilm_embeddings(search_string))\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        a.topic,\n",
    "        c.comment_text,\n",
    "        DOT_PRODUCT(c.comment_vector, JSON_ARRAY_PACK('{search_embedding_openai}')) AS openai_score,\n",
    "        DOT_PRODUCT(c.minilm_vector, JSON_ARRAY_PACK('{search_embedding_minilm}')) AS minilm_score,\n",
    "        c.post_shortcode\n",
    "    FROM\n",
    "        comments c\n",
    "    JOIN\n",
    "        posts a ON c.post_shortcode = a.post_shortcode\n",
    "    ORDER BY openai_score DESC\n",
    "    LIMIT 30;\n",
    "    \"\"\"\n",
    "\n",
    "    #print(query)\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        results = cursor.fetchall()\n",
    "\n",
    "        # Convert results to DataFrame\n",
    "        df = pd.DataFrame(results, columns=['Topic', 'Comment Text', 'openai_score','minilm_score', 'Post Shortcode'])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ff666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main interaction loop\n",
    "while True:\n",
    "    clear_screen()  # Clear the screen before each interaction\n",
    "    print(\"Choose an option:\")\n",
    "    print(\"1. Search for comments\")\n",
    "    print(\"2. Get Top brand\")\n",
    "    print(\"3. Exit\")\n",
    "    \n",
    "    option = input(\"Enter your choice (1/2/3): \")\n",
    "\n",
    "    if option == '1':\n",
    "        search_string = input('Please enter a search string comments: ')\n",
    "\n",
    "        # Call the function to fetch results\n",
    "        results_df = fetch_results(search_string)\n",
    "\n",
    "        # Format the DataFrame\n",
    "        formatted_df = format_dataframe(results_df)\n",
    "\n",
    "        # Display the results DataFrame with borders and lines using tabulate\n",
    "        print(tabulate(formatted_df, headers='keys', tablefmt='grid', showindex=False))\n",
    "        input('Press Enter to continue...')  # Wait for user input to continue\n",
    "        \n",
    "    elif option == '2':\n",
    "        search_string = input('Please enter a search string topic: ')\n",
    "        # Call the function to fetch top 5 results grouped by topic\n",
    "        top__results_df = fetch_top__results_grouped_by_topic(search_string)\n",
    "        formatted_df = format_dataframe(top__results_df)\n",
    "\n",
    "        # Display the top 5 results grouped by topic\n",
    "        print(tabulate(top__results_df, headers='keys', tablefmt='grid', showindex=False))\n",
    "        input('Press Enter to continue...')\n",
    "        \n",
    "    elif option == '3':\n",
    "        break  # Exit the loop if the user chooses to exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e2eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "if cursor:\n",
    "    cursor.close()\n",
    "if connection:\n",
    "    connection.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
